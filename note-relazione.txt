Su Monk Task 2 in generale:

- Il dataset era discretamente sbilanciato, per cui è importante notare che la misura di accuracy
non è totalmente veritiera. Per questo abbiamo utilizzato anche la balanced accuracy, che tiene conto
delle diverse proporzioni tra le classi

- Un dataset sbilanciato può anche influire negativamente sul training di un modello perché può portare
il modello a sviluppare un bias verso la majority class, rendendo difficile l'apprendimento e la
corretta classificazione della minority class.


****************************************************************

Su SVM per Monk Task 2:

- SVM per il Task 2 per fortuna da un 100% di accuracy, per cui il modello funziona bene. Nel caso un cui
avessimo avuto una accuracy più bassa, avremmo potuto provare tecniche di undersampling od oversampling,
rispettivamente Condensed Nearest Neighbor (CNN) e SMOTE.

- CNN è un algoritmo di undersampling (quindi agisce sulla majority class) che tende a preservare i dati
che si trovano sul decision boundary (ritenuti importanti per la classificazione) e a toglierne alcuni più
lontani da esso (meno importanti) al fine di bilanciare le due classi

- SMOTE è un algoritmo di oversampling (quindi agisce sulla minority class) che, in parole molto povere,
finché non ha bilanciato i dati delle due classi sceglie due punti della minority class, traccia una riga
immaginaria tra i due e crea un dato lungo questa linea (assegnato alla minority class).

- CNN è buono per SVM perché tende a preservare i dati sul decision boundary (per SVM, i support vector). SMOTE è
buono perché aggiunge dati che sono o inutili oppure sono dei support vector (nel caso in cui i due punti scelti
siano appunto dei vettori di supporto).

- C'è da dire che i dati sono molto pochi, per cui sarebbe stato preferibile SMOTE rispetto a CNN

- Ovviamente non serve scrivere tutto questo visto che non fa parte del programma, ma giusto un
accenno


****************************************************************

- Su Random Forest e NN per Monk Task 2

- Il Random Forest è ritenuto abbastanza robusto nei confronti dei dataset sbilanciati

- In generale comunque, sia Random Forest che NN possono essere provati con tecniche di undersampling/oversampling.


****************************************************************



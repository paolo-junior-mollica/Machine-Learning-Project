{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONK_TASK = 3\n",
    "USER = \"Nunzio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "if (colab := 'google.colab' in sys.modules):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_PATH = \"/content/drive/Shareddrives/Project_ML_23/\" + USER + \"/machine-learning-project\"\n",
    "    sys.path.insert(0,BASE_PATH)\n",
    "    sys.path.insert(0,BASE_PATH + \"src/utils\")\n",
    "    !pip install optuna\n",
    "    !pip install scikit-learn\n",
    "    !pip install scikeras\n",
    "    TRAIN_DATA = os.path.join(BASE_PATH, 'datasets', 'monk',f'monks-{MONK_TASK}.train')\n",
    "    TEST_DATA = os.path.join(BASE_PATH, 'datasets', 'monk',f'monks-{MONK_TASK}.test')\n",
    "    IMAGES_FOLDER = os.path.join(BASE_PATH, 'images', 'monk',  f'task-{MONK_TASK}', 'neural_network')\n",
    "    MODEL_FOLDER = os.path.join(BASE_PATH, 'trained_models', 'monk', f'task-{MONK_TASK}')\n",
    "else :   \n",
    "    TRAIN_DATA = os.path.join('..', '..', '..', 'datasets', 'monk', f'monks-{MONK_TASK}.train')\n",
    "    TEST_DATA = os.path.join('..', '..', '..', 'datasets', 'monk', f'monks-{MONK_TASK}.test')\n",
    "    IMAGES_FOLDER = os.path.join('..', '..', '..', 'images', 'monk', f'task-{MONK_TASK}', 'neural_network')\n",
    "    MODEL_FOLDER = os.path.join('..', '..', '..', 'trained_models', 'monk', f'task-{MONK_TASK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../utils')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set_theme(style='darkgrid')\n",
    "\n",
    "from utils import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To skip the first column (row indexes)\n",
    "columns_to_read = list(range(1, 8))\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_DATA, header=None, usecols=columns_to_read, delimiter=' ')\n",
    "df_test = pd.read_csv(TEST_DATA, header=None, usecols=columns_to_read, delimiter=' ')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['feature_' + str(i) for i in range(1, 7)]\n",
    "\n",
    "# Rename columns\n",
    "new_column_names = ['class'] + features\n",
    "\n",
    "df_train.columns = new_column_names\n",
    "df_test.columns = new_column_names\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_encoded = pd.get_dummies(df_train, columns=features)\n",
    "df_test_encoded = pd.get_dummies(df_test, columns=features)\n",
    "\n",
    "df_train_encoded, df_test_encoded = df_train_encoded.align(df_test_encoded, join='inner', axis=1)\n",
    "\n",
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = df_train_encoded.columns.difference(['class'])\n",
    "\n",
    "X_train = df_train_encoded[features].to_numpy()\n",
    "y_train = df_train_encoded['class'].to_numpy()\n",
    "\n",
    "X_test = df_test_encoded[features].to_numpy()\n",
    "y_test = df_test_encoded['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.src.regularizers import l2\n",
    "from keras.src.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(architecture=(8,), optimizer='adam', learning_rate=0.001, alpha=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=architecture[0], input_dim=X_train.shape[1], activation='relu',\n",
    "                    kernel_regularizer=l2(alpha)))\n",
    "\n",
    "    for units in architecture[1:]:\n",
    "        model.add(Dense(units=units, activation='relu', kernel_regularizer=l2(alpha)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__architecture': [\n",
    "        (8,), (8, 8), (8, 8, 8)\n",
    "    ],\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'model__learning_rate': [0.3],\n",
    "    'model__alpha': [0.9],\n",
    "    'epochs': [200],\n",
    "    'batch_size': [8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print('Best parameters: ', grid_search.best_params_)\n",
    "print('Best accuracy: ', grid_search.best_score_)\n",
    "print('Test set accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator=final_model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    train_sizes=[0.1, 0.33, 0.55, 0.78, 1.],\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Learning curve', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Training examples', fontweight='bold')\n",
    "plt.ylabel('Score', fontweight='bold')\n",
    "plt.grid(True)\n",
    "\n",
    "color1 = sns.dark_palette((20, 60, 50), input='husl')[-1]\n",
    "color2 = sns.dark_palette('seagreen')[-1]\n",
    "\n",
    "# Filling the area around the mean scores to indicate variability of the model's performance\n",
    "# The shaded area represents the range of scores (mean Â± standard deviation) for each training set size\n",
    "plt.fill_between(\n",
    "    train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=color1\n",
    ")\n",
    "plt.fill_between(\n",
    "    train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                 validation_scores_mean + validation_scores_std, alpha=0.2, color=color2\n",
    ")\n",
    "\n",
    "# Mean score lines for training and validation\n",
    "sns.lineplot(x=train_sizes, y=train_scores_mean, marker='s', color=color1, label='Training score')\n",
    "sns.lineplot(x=train_sizes, y=validation_scores_mean, marker='s', color=color2, label='Cross-validation score')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "save_plot(plt, IMAGES_FOLDER, 'learning_curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "model_path = os.path.join(MODEL_FOLDER, 'NN_model.joblib')\n",
    "dump(final_model, model_path, compress=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:50.908156Z",
     "start_time": "2023-12-28T15:01:50.907112Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Aggiungi il percorso della cartella che contiene utils.py a sys.path\n",
    "sys.path.append('../utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.061008Z",
     "start_time": "2023-12-28T15:01:50.908757Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from utils import save_plot, mean_euclidean_error, root_mean_squared_error, multidim_r2\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.063729Z",
     "start_time": "2023-12-28T15:01:51.062152Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = os.path.join('..', '..', 'datasets', 'cup2023', 'ML-CUP23-TR.csv')\n",
    "IMAGES_FOLDER = os.path.join('..', '..', 'images', 'cup2023', 'SVR')\n",
    "MODEL_FOLDER = os.path.join('..', '..', 'trained_models', 'cup2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.076544Z",
     "start_time": "2023-12-28T15:01:51.065029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         1         2         3         4         5         6         7   \\\n0 -0.917280 -0.712727 -0.989904  0.992819  0.993649  0.995543  0.711074   \n1 -0.858784  0.998755 -0.998396  0.999909  0.316503 -0.951897 -0.163139   \n2 -0.990441  0.958726 -0.998675  0.997216  0.987166  0.356483 -0.279689   \n3  0.937117  0.984474 -0.612420  0.999812  0.728623 -0.539962 -0.165939   \n4 -0.906628 -0.884567 -0.932487  0.941037  0.978134  0.998179  0.749606   \n\n         8         9         10         11         12         13  \n0  0.407645 -0.688548  0.616890   7.897453 -35.936382  21.077147  \n1  0.980982  0.661759 -0.800155  -9.330632  19.901571   6.069154  \n2  0.599163 -0.684630  0.922901  14.849400   3.374090  19.667479  \n3  0.999352 -0.921444 -0.974766 -46.591854  13.734777  17.953600  \n4 -0.590599 -0.508268  0.691798   8.217500 -45.885254  14.894251  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.917280</td>\n      <td>-0.712727</td>\n      <td>-0.989904</td>\n      <td>0.992819</td>\n      <td>0.993649</td>\n      <td>0.995543</td>\n      <td>0.711074</td>\n      <td>0.407645</td>\n      <td>-0.688548</td>\n      <td>0.616890</td>\n      <td>7.897453</td>\n      <td>-35.936382</td>\n      <td>21.077147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.858784</td>\n      <td>0.998755</td>\n      <td>-0.998396</td>\n      <td>0.999909</td>\n      <td>0.316503</td>\n      <td>-0.951897</td>\n      <td>-0.163139</td>\n      <td>0.980982</td>\n      <td>0.661759</td>\n      <td>-0.800155</td>\n      <td>-9.330632</td>\n      <td>19.901571</td>\n      <td>6.069154</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.990441</td>\n      <td>0.958726</td>\n      <td>-0.998675</td>\n      <td>0.997216</td>\n      <td>0.987166</td>\n      <td>0.356483</td>\n      <td>-0.279689</td>\n      <td>0.599163</td>\n      <td>-0.684630</td>\n      <td>0.922901</td>\n      <td>14.849400</td>\n      <td>3.374090</td>\n      <td>19.667479</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.937117</td>\n      <td>0.984474</td>\n      <td>-0.612420</td>\n      <td>0.999812</td>\n      <td>0.728623</td>\n      <td>-0.539962</td>\n      <td>-0.165939</td>\n      <td>0.999352</td>\n      <td>-0.921444</td>\n      <td>-0.974766</td>\n      <td>-46.591854</td>\n      <td>13.734777</td>\n      <td>17.953600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.906628</td>\n      <td>-0.884567</td>\n      <td>-0.932487</td>\n      <td>0.941037</td>\n      <td>0.978134</td>\n      <td>0.998179</td>\n      <td>0.749606</td>\n      <td>-0.590599</td>\n      <td>-0.508268</td>\n      <td>0.691798</td>\n      <td>8.217500</td>\n      <td>-45.885254</td>\n      <td>14.894251</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To skip the first column (row indexes)\n",
    "columns_to_read = list(range(1, 14))\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_DATA, header=None, comment='#', usecols=columns_to_read, delimiter=',')\n",
    "df_train = df_train.astype('float64') #casting\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.129555Z",
     "start_time": "2023-12-28T15:01:51.081931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n0  -0.917280  -0.712727  -0.989904   0.992819   0.993649   0.995543   \n1  -0.858784   0.998755  -0.998396   0.999909   0.316503  -0.951897   \n2  -0.990441   0.958726  -0.998675   0.997216   0.987166   0.356483   \n3   0.937117   0.984474  -0.612420   0.999812   0.728623  -0.539962   \n4  -0.906628  -0.884567  -0.932487   0.941037   0.978134   0.998179   \n\n   feature_7  feature_8  feature_9  feature_10   target_x   target_y  \\\n0   0.711074   0.407645  -0.688548    0.616890   7.897453 -35.936382   \n1  -0.163139   0.980982   0.661759   -0.800155  -9.330632  19.901571   \n2  -0.279689   0.599163  -0.684630    0.922901  14.849400   3.374090   \n3  -0.165939   0.999352  -0.921444   -0.974766 -46.591854  13.734777   \n4   0.749606  -0.590599  -0.508268    0.691798   8.217500 -45.885254   \n\n    target_z  \n0  21.077147  \n1   6.069154  \n2  19.667479  \n3  17.953600  \n4  14.894251  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>target_x</th>\n      <th>target_y</th>\n      <th>target_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.917280</td>\n      <td>-0.712727</td>\n      <td>-0.989904</td>\n      <td>0.992819</td>\n      <td>0.993649</td>\n      <td>0.995543</td>\n      <td>0.711074</td>\n      <td>0.407645</td>\n      <td>-0.688548</td>\n      <td>0.616890</td>\n      <td>7.897453</td>\n      <td>-35.936382</td>\n      <td>21.077147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.858784</td>\n      <td>0.998755</td>\n      <td>-0.998396</td>\n      <td>0.999909</td>\n      <td>0.316503</td>\n      <td>-0.951897</td>\n      <td>-0.163139</td>\n      <td>0.980982</td>\n      <td>0.661759</td>\n      <td>-0.800155</td>\n      <td>-9.330632</td>\n      <td>19.901571</td>\n      <td>6.069154</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.990441</td>\n      <td>0.958726</td>\n      <td>-0.998675</td>\n      <td>0.997216</td>\n      <td>0.987166</td>\n      <td>0.356483</td>\n      <td>-0.279689</td>\n      <td>0.599163</td>\n      <td>-0.684630</td>\n      <td>0.922901</td>\n      <td>14.849400</td>\n      <td>3.374090</td>\n      <td>19.667479</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.937117</td>\n      <td>0.984474</td>\n      <td>-0.612420</td>\n      <td>0.999812</td>\n      <td>0.728623</td>\n      <td>-0.539962</td>\n      <td>-0.165939</td>\n      <td>0.999352</td>\n      <td>-0.921444</td>\n      <td>-0.974766</td>\n      <td>-46.591854</td>\n      <td>13.734777</td>\n      <td>17.953600</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.906628</td>\n      <td>-0.884567</td>\n      <td>-0.932487</td>\n      <td>0.941037</td>\n      <td>0.978134</td>\n      <td>0.998179</td>\n      <td>0.749606</td>\n      <td>-0.590599</td>\n      <td>-0.508268</td>\n      <td>0.691798</td>\n      <td>8.217500</td>\n      <td>-45.885254</td>\n      <td>14.894251</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['feature_' + str(i) for i in range(1, 11)]\n",
    "targets = ['target_x', 'target_y', 'target_z']\n",
    "\n",
    "# Rename columns\n",
    "new_column_names = features + targets\n",
    "df_train.columns = new_column_names\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.130684Z",
     "start_time": "2023-12-28T15:01:51.086044Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train[features].to_numpy()\n",
    "y = df_train[targets].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #TODO split potenzialmente variabile?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.130914Z",
     "start_time": "2023-12-28T15:01:51.090044Z"
    }
   },
   "outputs": [],
   "source": [
    "mee_scorer = make_scorer(mean_euclidean_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "multidim_r2_scorer = make_scorer(multidim_r2, greater_is_better=True)\n",
    "\n",
    "scoring = {'MEE': mee_scorer, 'R2': multidim_r2_scorer, 'RMSE': rmse_scorer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definizione del modello SVR\n",
    "svr = svm.SVR()\n",
    "\n",
    "# Creazione di un MultiOutputRegressor\n",
    "model = MultiOutputRegressor(svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.131328Z",
     "start_time": "2023-12-28T15:01:51.097885Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'svr__estimator__C': [0.1, 1, 10, 100],\n",
    "    'svr__estimator__gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "    'svr__estimator__kernel' : ['rbf', 'linear', 'poly'],\n",
    "    'svr__estimator__epsilon': [0.01, 0.1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T15:01:51.149476Z",
     "start_time": "2023-12-28T15:01:51.101568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definizione del pipeline con RobustScaler e un modello Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\"\"\"\n",
    "Scales the input data using RobustScaler.\n",
    "\n",
    "in particular it uses the formula:\n",
    "    (X - X.median) / IQR\n",
    "where IQR is the interquartile range (75th - 25th percentile)\n",
    "\n",
    "we use the RobustScaler because it is robust to outliers. (it uses the median instead of the mean) TODO: do we have outliers?\n",
    "futhermore, it allows us to have una media di 0 e una varianza di 1, which is good for the neural network\n",
    "futhermor, it allows us to have a more rapid convergence of the gradient descent, and in general in the optimization algorithms\n",
    "inoltre ci permette di migliorare gli algo basati sulla distanza (es. KNN, clustering ierarchico), algoritmi che assumono normalità dei dati (alcuni metodi statistici), e algoritmi basati su gradient descent (reti neurali, regressione lineare) beneficiano particolarmente dello scaling.\n",
    "Non dovrebbero beneficiare particolarmente algo come il Random Forest, che non si basano su distanza, e non assumono normalità dei dati.\n",
    "Parameters:\n",
    "X_train (array-like): The input data to be scaled.\n",
    "\n",
    "Returns:\n",
    "scaled_data (array-like): The scaled data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('svr', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:44:32.992757Z",
     "start_time": "2023-12-28T15:01:51.106265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(\n\u001B[1;32m      2\u001B[0m     pipeline,\n\u001B[1;32m      3\u001B[0m     param_grid\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      9\u001B[0m )\n\u001B[0;32m---> 10\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    894\u001B[0m     )\n\u001B[1;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1422\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1420\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1421\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1422\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    842\u001B[0m         )\n\u001B[1;32m    843\u001B[0m     )\n\u001B[0;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    867\u001B[0m     )\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     64\u001B[0m )\n\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/joblib/parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[1;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/joblib/parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/data-spell-projects/machine-learning-project/venv/lib/python3.9/site-packages/joblib/parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[1;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[1;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[0;32m-> 1707\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[1;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[1;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='MEE',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Quando si utilizza grid_search.best_score_ in scikit-learn e si ottiene un valore negativo,\n",
    "ciò è tipicamente dovuto al fatto che scikit-learn trasforma alcune funzioni di scoring in modo \n",
    "che possano essere trattate come funzioni di \"massimizzazione\". '''\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_index = grid_search.best_index_\n",
    "\n",
    "mee = grid_search.best_score_\n",
    "r2 = grid_search.cv_results_['mean_test_R2'][best_index]\n",
    "rmse = grid_search.cv_results_['mean_test_RMSE'][best_index]\n",
    "\n",
    "print('Best parameters:', best_params)\n",
    "print('Best MEE score:', abs(mee))\n",
    "print('R2:', abs(r2))\n",
    "print('RMSE:', abs(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_params = {'C': best_params['svr__estimator__C'],\n",
    "                  'gamma': best_params['svr__estimator__gamma'],\n",
    "                  'kernel': best_params['svr__estimator__kernel'],\n",
    "                  'epsilon': best_params['svr__estimator__epsilon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definizione del modello SVR\n",
    "svr = svm.SVR(**adapted_params)\n",
    "\n",
    "# Creazione di un MultiOutputRegressor\n",
    "model = MultiOutputRegressor(svr)\n",
    "\n",
    "final_model = model\n",
    "\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator=final_model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    train_sizes=[0.1, 0.33, 0.55, 0.78, 1.],\n",
    "    cv=5,\n",
    "    scoring=mee_scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "validation_scores_std = np.std(validation_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Learning curve', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Training examples', fontweight='bold')\n",
    "plt.ylabel('Score', fontweight='bold')\n",
    "plt.grid(True)\n",
    "\n",
    "color1 = sns.dark_palette((20, 60, 50), input='husl')[-1]\n",
    "color2 = sns.dark_palette('seagreen')[-1]\n",
    "\n",
    "# Filling the area around the mean scores to indicate variability of the model's performance\n",
    "# The shaded area represents the range of scores (mean ± standard deviation) for each training set size\n",
    "plt.fill_between(\n",
    "    train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color=color1\n",
    ")\n",
    "plt.fill_between(\n",
    "    train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                 validation_scores_mean + validation_scores_std, alpha=0.2, color=color2\n",
    ")\n",
    "\n",
    "# Mean score lines for training and validation\n",
    "sns.lineplot(x=train_sizes, y=train_scores_mean, marker='s', color=color1, label='Training score')\n",
    "sns.lineplot(x=train_sizes, y=validation_scores_mean, marker='s', color=color2, label='Cross-validation score')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "save_plot(plt, IMAGES_FOLDER, 'learning_curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "mee = mean_euclidean_error(y_test, y_pred)\n",
    "r2 = multidim_r2(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MEE:', mee)\n",
    "print('R2:', r2)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(MODEL_FOLDER, 'SVR_model.joblib')\n",
    "dump(model, model_path, compress=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
